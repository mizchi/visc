#!/usr/bin/env node
/**
 * æ®‹ã‚Šã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
 * (yahoo, example, github)
 */

import puppeteer from 'puppeteer';
import { fetchRawLayoutData } from '../../src/browser/puppeteer.js';
import fs from 'fs/promises';
import path from 'path';

const REMAINING_SITES = [
  { name: 'example', url: 'https://example.com' },
  { name: 'github-mizchi', url: 'https://github.com/mizchi' },
  { name: 'yahoo', url: 'https://www.yahoo.co.jp' }, // æœ€å¾Œã«å®Ÿè¡Œ
];

const SAMPLES_PER_SITE = 5;
const OUTPUT_DIR = path.join(process.cwd(), 'tests', 'fixtures', 'calibration-samples');

async function collectRemainingSamples() {
  console.log('ğŸ¯ Collecting Remaining Calibration Samples');
  console.log('==========================================');
  console.log(`Sites to process: ${REMAINING_SITES.map(s => s.name).join(', ')}`);
  console.log('==========================================\n');

  const browser = await puppeteer.launch({
    headless: true,
    args: ['--no-sandbox', '--disable-setuid-sandbox']
  });

  try {
    for (const site of REMAINING_SITES) {
      const siteDir = path.join(OUTPUT_DIR, site.name);
      
      // æ—¢å­˜ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ç¢ºèª
      let existingSamples = 0;
      try {
        const files = await fs.readdir(siteDir);
        existingSamples = files.filter(f => f.startsWith('sample-')).length;
      } catch {
        // ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆ
        await fs.mkdir(siteDir, { recursive: true });
      }

      const samplesToCollect = SAMPLES_PER_SITE - existingSamples;
      
      if (samplesToCollect <= 0) {
        console.log(`âœ“ ${site.name}: Already has ${SAMPLES_PER_SITE} samples`);
        continue;
      }

      console.log(`\nğŸ“Š Collecting ${samplesToCollect} samples for ${site.name} (${site.url})`);
      console.log('-'.repeat(50));

      const page = await browser.newPage();
      await page.setViewport({ width: 1280, height: 800 });

      // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’çŸ­ã‚ã«è¨­å®š
      page.setDefaultNavigationTimeout(20000);
      page.setDefaultTimeout(15000);

      const metadata = {
        site: site.name,
        url: site.url,
        collectedAt: new Date().toISOString(),
        viewport: { width: 1280, height: 800 },
        sampleCount: SAMPLES_PER_SITE,
        samples: [] as any[]
      };

      for (let i = existingSamples + 1; i <= SAMPLES_PER_SITE; i++) {
        console.log(`  Sample ${i}/${SAMPLES_PER_SITE}...`);
        
        try {
          await page.goto(site.url, { 
            waitUntil: 'domcontentloaded', // ã‚ˆã‚Šé€Ÿã„èª­ã¿è¾¼ã¿
            timeout: 20000 
          });

          // è¿½åŠ ã®å¾…æ©Ÿï¼ˆå‹•çš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”¨ï¼‰
          await new Promise(resolve => setTimeout(resolve, 2000));

          const rawData = await fetchRawLayoutData(page, {
            waitForContent: false, // é«˜é€ŸåŒ–ã®ãŸã‚ç„¡åŠ¹åŒ–
            captureFullPage: false
          });

          const sampleFilename = `sample-${i}.json`;
          const samplePath = path.join(siteDir, sampleFilename);
          
          await fs.writeFile(
            samplePath,
            JSON.stringify(rawData, null, 2)
          );

          metadata.samples.push({
            index: i,
            filename: sampleFilename,
            elementCount: rawData.elements.length
          });

          console.log(`    âœ“ Saved: ${sampleFilename} (${rawData.elements.length} elements)`);

        } catch (error: any) {
          console.log(`    âš ï¸  Failed to collect sample ${i}: ${error.message}`);
          // ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ç¶šè¡Œ
        }

        // ã‚µãƒ³ãƒ—ãƒ«é–“ã§å°‘ã—å¾…æ©Ÿ
        if (i < SAMPLES_PER_SITE) {
          await new Promise(resolve => setTimeout(resolve, 1500));
        }
      }

      // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
      await fs.writeFile(
        path.join(siteDir, 'metadata.json'),
        JSON.stringify(metadata, null, 2)
      );

      console.log(`  âœ… Completed: ${metadata.samples.length} samples collected`);
      
      await page.close();
    }

    // å…¨ä½“ã®ã‚µãƒãƒªãƒ¼ã‚’æ›´æ–°
    const allSites = ['zenn', 'yahoo', 'example', 'github-mizchi'];
    let totalCollected = 0;
    const siteStats = [];

    for (const siteName of allSites) {
      try {
        const files = await fs.readdir(path.join(OUTPUT_DIR, siteName));
        const sampleCount = files.filter(f => f.startsWith('sample-')).length;
        totalCollected += sampleCount;
        siteStats.push({ name: siteName, sampleCount });
      } catch {
        siteStats.push({ name: siteName, sampleCount: 0 });
      }
    }

    const summary = {
      collectionDate: new Date().toISOString(),
      sites: siteStats,
      totalSamples: totalCollected
    };

    await fs.writeFile(
      path.join(OUTPUT_DIR, 'summary.json'),
      JSON.stringify(summary, null, 2)
    );

    console.log('\n==========================================');
    console.log('âœ… Collection complete!');
    console.log(`Total samples collected: ${totalCollected}`);
    console.log('Site breakdown:');
    siteStats.forEach(stat => {
      console.log(`  - ${stat.name}: ${stat.sampleCount} samples`);
    });
    
  } catch (error) {
    console.error('âŒ Error collecting samples:', error);
    throw error;
  } finally {
    await browser.close();
  }
}

// ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãã§å®Ÿè¡Œ
collectRemainingSamples().catch(error => {
  console.error('Fatal error:', error);
  process.exit(1);
});